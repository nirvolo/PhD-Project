par(mfrow = c(3,3))
for(cnty in unique(fun99_new$county)[1:9]){
min_temp = min(fun99_new$TMIN[fun99_new$county == cnty])
max_temp = max(fun99_new$TMAX[fun99_new$county == cnty])
plot(days, fun99_new$TMIN[fun99_new$county == cnty], type = 'l', ylab = "Temperature",
ylim = c(min_temp, max_temp), main = cnty)
lines(days, fun99_new$TMAX[fun99_new$county == cnty], col = "blue")
}
par(mfrow = c(3,3))
for(cnty in unique(fun99_new$county)[62:70]){
min_temp = min(fun99_new$TMIN[fun99_new$county == cnty])
max_temp = max(fun99_new$TMAX[fun99_new$county == cnty])
plot(days, fun99_new$TMIN[fun99_new$county == cnty], type = 'l', ylab = "Temperature",
ylim = c(min_temp, max_temp), main = cnty)
lines(days, fun99_new$TMAX[fun99_new$county == cnty], col = "blue")
}
# County 1
plot(days, fun99_new$TMIN[fun99_new$county == "allen"], type = 'l', xlab = "day", ylab = "temperature (C)",
ylim = c(min(fun99_new$TMIN[fun99_new$county == "allen"]), max(fun99_new$TMAX[fun99_new$county == "allen"])),
main = "ALLEN")
lines(days, fun99_new$TMAX[fun99_new$county == "allen"], col = "blue")
legend( x = "topright",
legend = c("Min Temp","Max Temp"),
col = c("black","blue"), lwd=1, lty=c(1,1), cex = 1)
# Using ggplot
# allen_county_data = data.frame(matrix(c(fun99_new$TMIN[fun99_new$county == "allen"],fun99_new$TMAX[fun99_new$county == "allen"],days), nrow = length(days), ncol = 3))
# colnames(allen_county_data) = c("Min. Temp","Max. Temp", "days")
#
# ggplot() +
#   geom_line(mapping = aes(x = days, y =  fun99_new$TMIN[fun99_new$county == "allen"])) +
#   geom_line(mapping = aes(x = days, y =  fun99_new$TMAX[fun99_new$county == "allen"]),color = "blue", linetype = "dashed") +
#   labs(colour = )
# Atchison County
plot(days, fun99_new$TMIN[fun99_new$county == "atchison"], type = 'l', ylab = "Temperature",
ylim = c(min(fun99_new$TMIN[fun99_new$county == "atchison"]), max(fun99_new$TMAX[fun99_new$county == "atchison"])),
main = "ATCHISON")
lines(days, fun99_new$TMAX[fun99_new$county == "atchison"], col = "blue")
# Cowley County
plot(days, fun99_new$TMIN[fun99_new$county == "cowley"], type = 'l', ylab = "Temperature",
ylim = c(min(fun99_new$TMIN[fun99_new$county == "cowley"]), max(fun99_new$TMAX[fun99_new$county == "cowley"])),
main = "COWLEY")
lines(days, fun99_new$TMAX[fun99_new$county == "cowley"], col = "blue")
# boxplot of the minimum temperatures
boxplot(TMIN ~ county, data = fun99_new[fun99_new$CountyI <= 18,], ylab = 'Min Temp', xlab = "County", main = "Min Temp vs. County")
# boxplot of the maximum temperatures
boxplot(TMAX ~ county, data = fun99_new[fun99_new$CountyI <= 18,], ylab = 'Max Temp', xlab = "County", main = "Max Temp vs. County")
boxplot(TMIN ~ CountyI, data = fun99_new, ylab = 'Min Temp', xlab = "County", main = "Min Temp vs. County")
boxplot(TMAX ~ CountyI, data = fun99_new, ylab = 'Min Temp', xlab = "County", main = "Max Temp vs. County")
# Histogram of avg precipitation
hist(reg99$avgPRCP, xlab = "average precipitation", main = "Average Precipitation")
boxplot(reg99$avgPRCP)
# Summary statistics of a few counties temperature
stat_min = matrix(data = NA,nrow = 6, ncol = 9)
stat_max = matrix(data = NA,nrow = 6, ncol = 9)
for(i in 1:9){
id = unique(fun99_new$CountyI)[i]
stat_min[,i] = summary(fun99_new[fun99_new$CountyI == id, c("TMIN")])
stat_max[,i] = summary(fun99_new[fun99_new$CountyI == id, c("TMAX")])
}
stat_min
stat_max
# Summary statistics of a few counties temperature
stat_min = matrix(data = NA,nrow = 6, ncol = 9)
stat_max = matrix(data = NA,nrow = 6, ncol = 9)
for(i in 1:9){
id = unique(fun99_new$CountyI)[i]
stat_min[,i] = summary(fun99_new[fun99_new$CountyI == id, c("TMIN")])
stat_max[,i] = summary(fun99_new[fun99_new$CountyI == id, c("TMAX")])
}
# Calculating the variance
var_min = rep(0, 9)
var_max = rep(0, 9)
for(i in 1:9){
id = unique(fun99_new$CountyI)[i]
var_min[i] = var(fun99_new[fun99_new$CountyI == id, c("TMIN")])
var_max[i] = var(fun99_new[fun99_new$CountyI == id, c("TMAX")])
}
# Histogram of the crop yield
hist(reg99$Yield)
boxplot(reg99$Yield)
# Not sure if this is meaningful but plotting the mean min/max temp against the avg crop yield for
# a few counties
min_avg = rep(0, length(unique(fun99_new$county)))
max_avg = rep(0, length(unique(fun99_new$county)))
for(i in 1:length(unique(fun99_new$CountyI))){
id = unique(fun99_new$CountyI)[i]
min_avg[i] = mean(fun99_new$TMIN[fun99_new$CountyI == id])
print(min_avg[i])
max_avg[i] = mean(fun99_new$TMAX[fun99_new$CountyI == id])
}
# The average crop yield for 74 counties
yield = reg99$Yield[reg99$CountyI]
# Plot of yield vs. min_avg
par(mfrow = c(1,2))
plot(min_avg, yield)
plot(max_avg, yield)
# Not sure if this is meaningful but plotting the mean min/max temp against the avg crop yield for
# a few counties
min_avg = rep(0, length(unique(fun99_new$county)))
max_avg = rep(0, length(unique(fun99_new$county)))
for(i in 1:length(unique(fun99_new$CountyI))){
id = unique(fun99_new$CountyI)[i]
min_avg[i] = mean(fun99_new$TMIN[fun99_new$CountyI == id])
#print(min_avg[i])
max_avg[i] = mean(fun99_new$TMAX[fun99_new$CountyI == id])
}
# The average crop yield for 74 counties
yield = reg99$Yield[reg99$CountyI]
# Plot of yield vs. min_avg
par(mfrow = c(1,2))
plot(min_avg, yield)
plot(max_avg, yield)
# Plot of yield vs. precipitation
plot(reg99$avgPRCP, yield, xlab = "precipitation", main = "Yield vs. Precipitation")
# Plot of the maximum temperature curves over a few years for the first 9 counties
#  matplot(dat, type = c("b"),pch=1,col = 1:4)
# aa = matrix(data = c(temp_df[temp_df$county == "allen",]$TMAX), nrow = 365, ncol = 12)
# aa_avg = apply(aa, 1, mean)
# matplot(aa, type = "l", col = 1:12, lty = 1)
# lines(aa_avg, col = "red", lwd = 2)
par(mfrow = c(3,3))
for(cnty in unique(temp_df$county)[1:9]){
yrs = dim(temp_df[temp_df$county == cnty,])[1]/365
#print(yrs)
max_df = matrix(data = c(temp_df[temp_df$county == cnty,]$TMAX), nrow = 365, ncol = yrs)
matplot(max_df, type = "l", col = 1:yrs, lty = 1, xlab = "day", ylab = "max temp", main = cnty)
}
# Same kind of plot as above just for the last 9 counties
par(mfrow = c(3,3))
for(cnty in unique(temp_df$county)[76:84]){
yrs = dim(temp_df[temp_df$county == cnty,])[1]/365
#print(yrs)
max_df = matrix(data = c(temp_df[temp_df$county == cnty,]$TMAX), nrow = 365, ncol = yrs)
matplot(max_df, type = "l", col = 1:yrs, lty = 1, xlab = "day", ylab = "max temp", main = cnty)
}
# Some of the individual plots over all years
# Allen county
matplot(matrix(data = c(temp_df[temp_df$county == "allen",]$TMAX),
nrow = 365, ncol = dim(temp_df[temp_df$county == "allen",])[1]/365),
type = "l", col = 1:yrs, lty = 1, xlab = "day", ylab = "max temp", main = "allen")
matplot(matrix(data = c(temp_df[temp_df$county == "trego",]$TMAX),
nrow = 365, ncol = dim(temp_df[temp_df$county == "allen",])[1]/365),
type = "l", col = 1:yrs, lty = 1, xlab = "day", ylab = "max temp", main = "trego")
# Wilson county
matplot(matrix(data = c(temp_df[temp_df$county == "wilson",]$TMAX),
nrow = 365, ncol = dim(temp_df[temp_df$county == "wilson",])[1]/365),
type = "l", col = 1:yrs, lty = 1, xlab = "day", ylab = "max temp", main = "wilson")
# Plotting the minimum temp curves over all years for the first 9 counties
par(mfrow = c(3,3))
for(cnty in unique(temp_df$county)[1:9]){
yrs = dim(temp_df[temp_df$county == cnty,])[1]/365
max_df = matrix(data = c(temp_df[temp_df$county == cnty,]$TMIN), nrow = 365, ncol = yrs)
matplot(max_df, type = "l", col = 1:yrs, lty = 1, xlab = "day", ylab = "min temp", main = cnty)
}
# Plotting the minimum temp curves over all years for the last 9 counties
par(mfrow = c(3,3))
for(cnty in unique(temp_df$county)[76:84]){
yrs = dim(temp_df[temp_df$county == cnty,])[1]/365
max_df = matrix(data = c(temp_df[temp_df$county == cnty,]$TMIN), nrow = 365, ncol = yrs)
matplot(max_df, type = "l", col = 1:yrs, lty = 1, xlab = "day", ylab = "min temp", main = cnty)
}
# Randomly picking 50 curve trajectories from all counties and years
set.seed(112922)
pairs = matrix(0, nrow = 1, ncol = 2)
#i = 1
while(dim(pairs)[1] <= 50){
yr = sample(unique(temp_df$Year),size = 1)
cnty = sample(unique(temp_df$county),size = 1)
# I added the row c(0,0) since if there is only one pair
# in py it treats it as a vector and then when indexing
# py[,2], it doesn't work since this is for matrices. So
# that the command py[,2] works, we default py to always
# be a matrix.
py = rbind(c(0, 0), pairs[pairs[,1] == yr,])
# Checking if the cnty has been chosen already and if
# the pair (cnty,year) has yield data or not in corn.
print(length(corn$County[corn$Year == yr & corn$County == cnty]))
if (!(cnty %in% py[,2]) & length(corn$County[corn$Year == yr & corn$County == cnty]) > 0){
pairs = rbind(pairs,c(yr,cnty))
}
#i = i+1
}
# Removing the first row of pairs since it is (0,0)
pairs = pairs[-1,]
# Randomly picking 50 curve trajectories from all counties and years
set.seed(112922)
pairs = matrix(0, nrow = 1, ncol = 2)
while(dim(pairs)[1] <= 50){
yr = sample(unique(temp_df$Year),size = 1)
cnty = sample(unique(temp_df$county),size = 1)
# I added the row c(0,0) since if there is only one pair
# in py it treats it as a vector and then when indexing
# py[,2], it doesn't work since this is for matrices. So
# that the command py[,2] works, we default py to always
# be a matrix.
py = rbind(c(0, 0), pairs[pairs[,1] == yr,])
# Checking if the cnty has been chosen already and if
# the pair (cnty,year) has yield data or not in corn.
print(length(corn$County[corn$Year == yr & corn$County == cnty]))
if (!(cnty %in% py[,2]) & length(corn$County[corn$Year == yr & corn$County == cnty]) > 0){
pairs = rbind(pairs,c(yr,cnty))
}
}
# Removing the first row of pairs since it is (0,0)
pairs = pairs[-1,]
# Randomly picking 50 curve trajectories from all counties and years
set.seed(112922)
pairs = matrix(0, nrow = 1, ncol = 2)
while(dim(pairs)[1] <= 50){
yr = sample(unique(temp_df$Year),size = 1)
cnty = sample(unique(temp_df$county),size = 1)
# I added the row c(0,0) since if there is only one pair
# in py it treats it as a vector and then when indexing
# py[,2], it doesn't work since this is for matrices. So
# that the command py[,2] works, we default py to always
# be a matrix.
py = rbind(c(0, 0), pairs[pairs[,1] == yr,])
if (!(cnty %in% py[,2]) & length(corn$County[corn$Year == yr & corn$County == cnty]) > 0){
pairs = rbind(pairs,c(yr,cnty))
}
}
# Removing the first row of pairs since it is (0,0)
pairs = pairs[-1,]
# Plot of 50 minimum temperature curves
par(mfrow = c(1, 1))
mean_min = rep(0, 365)
plot(NA, xlim = c(1,365), ylim = c(min(temp_df$TMIN),max(temp_df$TMAX)), xlab = "day", ylab = "temperature (C)",
main = "Minimum Temperature")
for(i in 1:dim(pairs)[1]){
yr = pairs[i,1]
cnty = pairs[i,2]
min_temp = temp_df[temp_df$Year == yr & temp_df$county == cnty,]$TMIN
mean_min = mean_min + min_temp
lines(min_temp)
}
mean_min = mean_min/49
lines(mean_min, col="red")
# Plot of 50 maximum temperature curves
par(mfrow = c(1, 1))
plot(NA, xlim = c(1,365), ylim = c(min(temp_df$TMIN),max(temp_df$TMAX)), xlab = "day", ylab = "temperature (C)",
main = "Maximum Temperature")
mean_max = rep(0, 365)
for(i in 1:dim(pairs)[1]){
yr = pairs[i,1]
cnty = pairs[i,2]
max_temp = temp_df[temp_df$Year == yr & temp_df$county == cnty,]$TMAX
if (length(max_temp) < 365) print(c(yr, cnty))
#print(length(max_temp))
mean_max = mean_max + max_temp
lines(max_temp)
}
mean_max = mean_max/49
lines(mean_max, col="red")
### **Need to run in console** ###
# load("Data_Extraction_cleaning/Rdatafiles/RawMidwestFundatPreProc_incl_irrig.RData")
# load("Data_Extraction_cleaning/Rdatafiles/RawMidwestRegdatPreProc_incl_irrig.RData")
####### Calculating the average yield per year for Midwest #######
midw_avg_yield_per_year = c()
unq_yrs = sort(unique(midw_regdat_new$Year))
load("Data_Extraction_cleaning/Rdatafiles/RawMidwestFundatPreProc_incl_irrig.RData")
load("Data_Extraction_cleaning/Rdatafiles/RawMidwestRegdatPreProc_incl_irrig.RData")
### **Need to run in console** ###
# load("Data_Extraction_cleaning/Rdatafiles/RawMidwestFundatPreProc_incl_irrig.RData")
# load("Data_Extraction_cleaning/Rdatafiles/RawMidwestRegdatPreProc_incl_irrig.RData")
####### Calculating the average yield per year for Midwest #######
midw_avg_yield_per_year = c()
unq_yrs = sort(unique(midw_regdat_new$Year))
for(i in 1:length(unq_yrs)){
yr = unq_yrs[i]
midw_avg_yield_per_year[i] = mean(midw_regdat_new[midw_regdat_new$Year == yr, "Yield"])
}
midw_avg_yield_per_year
midw_avg_yield_df = data.frame(matrix(c(unq_yrs,midw_avg_yield_per_year), nrow = 21, ncol = 2))
colnames(midw_avg_yield_df) = c("Year","AverageYield")
ggplot(data = midw_avg_yield_df, mapping = aes(x = Year, y = AverageYield)) +
geom_point() + geom_line() + xlab("Year") + ylab("Average Yield") + xlim(c(1999,2020))
length(unq_yrs)
### **Need to run in console** ###
# load("Data_Extraction_cleaning/Rdatafiles/RawMidwestFundatPreProc_incl_irrig.RData")
# load("Data_Extraction_cleaning/Rdatafiles/RawMidwestRegdatPreProc_incl_irrig.RData")
####### Calculating the average yield per year for Midwest #######
midw_avg_yield_per_year = c()
unq_yrs = sort(unique(midw_regdat_new$Year))
for(i in 1:length(unq_yrs)){
yr = unq_yrs[i]
midw_avg_yield_per_year[i] = mean(midw_regdat_new[midw_regdat_new$Year == yr, "Yield"])
}
midw_avg_yield_df = data.frame(matrix(c(unq_yrs,midw_avg_yield_per_year), nrow = 21, ncol = 2))
colnames(midw_avg_yield_df) = c("Year","AverageYield")
ggplot(data = midw_avg_yield_df, mapping = aes(x = Year, y = AverageYield)) +
geom_point() + geom_line() + xlab("Year") + ylab("Average Yield") + xlim(c(1999,2020))
# Generating grid points based on the scaled boundaries of Kansas.
#summary(scl_locs)
uu = seq(-3.65, 2.5, length.out = 40) # longitude
vv = seq(-1.45, 1.45, length.out = 40) # latitude
n1 = length(uu)
n2 = length(vv)
u = rep(uu,n2) # repeats the vector uu 10 times
v = rep(vv,rep(n1,n2)) # repeats each value in vv 10 times
grid_pts = matrix(c(u,v), nrow = length(u), ncol = 2)
########################## Heat Maps for Constant Functions #########################
sim_new_otpt_const = sim_fxn_new(N = N, phi = phi, v = fd_err, sp_locs = scl_locs, years = yrs, n_folds = flds, fld_lim = 1,
coef_comp = "const", snr = SNR, comp_model = T, num_iter = 1, spat_corr = T, d = 3, tri_fin = 2, models = c("svfm"),
reval = c(0,1), log.lam = c(-15.5,-8), family = gaussian())
N = 100 # number of time points
fd_err = sqrt(0.2) # sd of error (functional predictor)
# Matern corr. fxn parameter that controls rate of decay. Dividing by 111 km since
# 50 is in kilometer units, not lat and long units. The distance that's calculated
# in the simulation is between lat and long units.
phi = 50/111
# Iterating over the different settings
yrs = 10 # Change to 10
flds = 5 # Change to 5
n_iter = 25 # number of iterations
SNR = 3.3
flds = 5
yrs = 10
# Generating grid points based on the scaled boundaries of Kansas.
#summary(scl_locs)
uu = seq(-3.65, 2.5, length.out = 40) # longitude
vv = seq(-1.45, 1.45, length.out = 40) # latitude
n1 = length(uu)
n2 = length(vv)
u = rep(uu,n2) # repeats the vector uu 10 times
v = rep(vv,rep(n1,n2)) # repeats each value in vv 10 times
grid_pts = matrix(c(u,v), nrow = length(u), ncol = 2)
########################## Heat Maps for Constant Functions #########################
sim_new_otpt_const = sim_fxn_new(N = N, phi = phi, v = fd_err, sp_locs = scl_locs, years = yrs, n_folds = flds, fld_lim = 1,
coef_comp = "const", snr = SNR, comp_model = T, num_iter = 1, spat_corr = T, d = 3, tri_fin = 2, models = c("svfm"),
reval = c(0,1), log.lam = c(-15.5,-8), family = gaussian())
# Calculating the estimated coefficients for the grid points based on the training model fit
const_sim_fit = sim_new_otpt_const$svfm
grid_coefs_const = coef_fxns(locs = grid_pts, coef = "const")
est_coefs_const = BQ2_grid%*%const_sim_fit$svfm_fit$theta_hat
#grid_coefs = coef_fxns(locs = grid_pts, coef = func_type)
#est_coefs = BQ2_grid%*%best_fit$theta_hat
var = 1
for (var in 1:7){
par(mfrow = c(1,2))
# I added 0.5 here since the function image2D has an issue with negative z values.
# Adding 0.5 so the values are positive
# I also don't need the contour line of code, just by adding the argument contour = T for image2D does the job
image2D(z = matrix(grid_coefs_const[,var] + 0.5,n1,n2), x = uu, y = vv, col = heat.colors(5), contour = T)
#contour(uu,vv, matrix(grid_coefs_const[,var] + 0.5,n1,n2), add = TRUE, drawlabels = TRUE)
# Creating a heatmap for the estimated coefficients based on the grid points
image2D(z = matrix(est_coefs_const[,var] + 0.5, n1, n2), x = uu, y = vv, col = heat.colors(5), contour = T)
#matrix(est_coefs[,2], n1, n2)
#contour(uu,vv, matrix(est_coefs_const[,var] + 0.5, n1, n2), add = TRUE, drawlabels = TRUE)
}
########################## Heat Maps for Constant Functions #########################
sim_new_otpt_const = sim_fxn_new(N = N, phi = phi, v = fd_err, sp_locs = scl_locs, years = yrs, n_folds = flds, fld_lim = 1,
coef_comp = "const", snr = SNR, comp_model = T, num_iter = 1, spat_corr = T, d = 3, tri_fin = 2, models = c("svfm"),
reval = c(0,1), log.lam = c(-15.5,-8), family = gaussian())
# Calculating the estimated coefficients for the grid points based on the training model fit
const_sim_fit = sim_new_otpt_const$svfm
grid_coefs_const = coef_fxns(locs = grid_pts, coef = "const")
est_coefs_const = BQ2_grid%*%const_sim_fit$svfm_fit$theta_hat
#grid_coefs = coef_fxns(locs = grid_pts, coef = func_type)
#est_coefs = BQ2_grid%*%best_fit$theta_hat
var = 1
for (var in 1:7){
par(mfrow = c(1,2))
# I added 0.5 here since the function image2D has an issue with negative z values.
# Adding 0.5 so the values are positive
# I also don't need the contour line of code, just by adding the argument contour = T for image2D does the job
image2D(z = matrix(grid_coefs_const[,var] + 0.5,n1,n2), x = uu, y = vv, col = heat.colors(5), contour = T)
#contour(uu,vv, matrix(grid_coefs_const[,var] + 0.5,n1,n2), add = TRUE, drawlabels = TRUE)
# Creating a heatmap for the estimated coefficients based on the grid points
image2D(z = matrix(est_coefs_const[,var] + 0.5, n1, n2), x = uu, y = vv, col = heat.colors(5), contour = T)
#matrix(est_coefs[,2], n1, n2)
#contour(uu,vv, matrix(est_coefs_const[,var] + 0.5, n1, n2), add = TRUE, drawlabels = TRUE)
}
const_sim_fit = sim_new_otpt_const$svfm
grid_coefs_const = coef_fxns(locs = grid_pts, coef = "const")
est_coefs_const = BQ2_grid%*%const_sim_fit$svfm_fit$theta_hat
var = 1
for (var in 1:7){
par(mfrow = c(1,2))
# I added 0.5 here since the function image2D has an issue with negative z values.
# Adding 0.5 so the values are positive
# I also don't need the contour line of code, just by adding the argument contour = T for image2D does the job
image2D(z = matrix(grid_coefs_const[,var] + 0.5,n1,n2), x = uu, y = vv, col = heat.colors(5), contour = T)
#contour(uu,vv, matrix(grid_coefs_const[,var] + 0.5,n1,n2), add = TRUE, drawlabels = TRUE)
# Creating a heatmap for the estimated coefficients based on the grid points
image2D(z = matrix(est_coefs_const[,var] + 0.5, n1, n2), x = uu, y = vv, col = heat.colors(5), contour = T)
#matrix(est_coefs[,2], n1, n2)
#contour(uu,vv, matrix(est_coefs_const[,var] + 0.5, n1, n2), add = TRUE, drawlabels = TRUE)
}
########################## Heat Maps for Basic Functions #########################
sim_new_otpt_basic = sim_fxn_new(N = N, phi = phi, v = fd_err, sp_locs = scl_locs, years = yrs, n_folds = flds, fld_lim = 1,
coef_comp = "basic", snr = SNR, comp_model = F, num_iter = 1, spat_corr = T, d = 3, tri_fin = 2,
models = c("svfm"), reval = c(0,1), log.lam = c(-15.5,-8), family = gaussian())
# Calculating the estimated coefficients for the grid points based on the training model fit
basic_sim_fit = sim_new_otpt_basic$svfm
grid_coefs_basic = coef_fxns(locs = grid_pts, coef = "basic")
est_coefs_basic = BQ2_grid%*%basic_sim_fit$svfm_fit$theta_hat
# Heat maps for each of the coefficients. Comparing true and estimated
for(var in 1:7){
par(mfrow = c(1,2))
# I also don't need the contour line of code, just by adding the argument contour = T for image2D does the job
#if(var <= 2) htmp_main = paste("alpha", var-1)
#else htmp_main = paste("beta", var-2)
# if(var <= 2){
#   var_num = var-1
#   htmp_main_true = substitute(expression(paste('True ',alpha[var_num], ' (linear)')),list(var_num=var_num))
#   htmp_main_est = substitute(expression(paste('Est. ',alpha[var_num], ' (linear)')),list(var_num=var_num))
# }
# else{
#   var_num = var-2
#   htmp_main_true = substitute(expression(paste('True ',beta[var_num], ' (linear)')),list(var_num=var_num))
#   htmp_main_est = substitute(expression(paste('Est. ',beta[var_num], ' (linear)')),list(var_num=var_num))
# }
# image2D(z = matrix(grid_coefs_basic[,var],n1,n2), x = uu, y = vv, col = heat.colors(5), contour = T, main = paste("true",htmp_main, "(linear)"))
image2D(z = matrix(grid_coefs_basic[,var],n1,n2), x = uu, y = vv, col = heat.colors(5), contour = T, main =
"True")
# Creating a heatmap for the estimated coefficients based on the grid points
image2D(z = matrix(est_coefs_basic[,var], n1, n2), x = uu, y = vv, col = heat.colors(5), contour = T, main =
"Estimated")
}
########################## Heat Maps for Complex Functions #########################
sim_new_otpt_comp = sim_fxn_new(N = N, phi = phi, v = fd_err, sp_locs = scl_locs, years = yrs, n_folds = flds, fld_lim = 1,
coef_comp = "complex", snr = SNR, comp_model = F, num_iter = 1, spat_corr = T, d = 3, tri_fin = 2, models = c("svfm"),
reval = c(0,1), log.lam = c(-15.5,-8), family = gaussian())
# Calculating the estimated coefficients for the grid points based on the training model fit
comp_sim_fit = sim_new_otpt_comp$svfm
grid_coefs_comp = coef_fxns(locs = grid_pts, coef = "complex")
est_coefs_comp = BQ2_grid%*%comp_sim_fit$svfm_fit$theta_hat
# Heat maps for each of the coefficients. Comparing true and estimated
for(var in 1:7){
par(mfrow = c(1,2))
image2D(z = matrix(grid_coefs_comp[,var],n1,n2), x = uu, y = vv, col = heat.colors(5), contour = T, main = "True")
# Creating a heatmap for the estimated coefficients based on the grid points
image2D(z = matrix(est_coefs_comp[,var], n1, n2), x = uu, y = vv, col = heat.colors(5), contour = T, main = "Estimate")
}
#### Creating eigenfunction plots for Kansas ########
# load("Data_Extraction_cleaning/RdataFiles/NewKansasFromMidw_PreProcRegdat.RData")
# load("Data_Extraction_cleaning/RdataFiles/NewKansasFromMidw_PreProcFundat.RData")
ag_data_otpt_new_kns = ag.data_cv.fxn_nopresmooth(fundat_all = kns_fd_new, nonfd = kns_nonfd_new, thresh = 0.95, n_fold = 5, iter = 1, deg = 3, DE_MEAN_RESP = T,
pred_vars = c("avgPRCP","irrig_prop"), reval = c(0,1), fld_lim = 1)
load("Data_Extraction_cleaning/RdataFiles/NewKansasFromMidw_PreProcRegdat.RData")
load("Data_Extraction_cleaning/RdataFiles/NewKansasFromMidw_PreProcFundat.RData")
#### Creating eigenfunction plots for Kansas ########
# load("Data_Extraction_cleaning/RdataFiles/NewKansasFromMidw_PreProcRegdat.RData")
# load("Data_Extraction_cleaning/RdataFiles/NewKansasFromMidw_PreProcFundat.RData")
ag_data_otpt_new_kns = ag.data_cv.fxn_nopresmooth(fundat_all = kns_fd_new, nonfd = kns_nonfd_new, thresh = 0.95, n_fold = 5, iter = 1, deg = 3, DE_MEAN_RESP = T,
pred_vars = c("avgPRCP","irrig_prop"), reval = c(0,1), fld_lim = 1)
par(mfrow = c(3,2))
for(i in 1:6){
plot(ag_data_otpt_new_kns$train_mod$fpca_obj$harmonics[i], xlab = "time", ylab = "", main = paste("FPC",i), ylim = c(-2,2))
}
######### Heat maps for the true coefficient functions for Kansas ##########
#### Generating the grid points
uu = seq(-3.65, 2.5, length.out = 40) # longitude
vv = seq(-1.45, 1.45, length.out = 40) # latitude
n1 = length(uu)
n2 = length(vv)
u = rep(uu,n2) # repeats the vector uu 10 times
v = rep(vv,rep(n1,n2)) # repeats each value in vv 10 times
grid_pts = matrix(c(u,v), nrow = length(u), ncol = 2)
# load bivariate basis for the grid pts I generated above
B0_grid = basis(kns_tri2$V, kns_tri2$Tr, d = 3, r = 1, grid_pts)
Q2_grid = B0_grid$Q2
BQ2_grid = as.matrix(B0_grid$B%*%Q2_grid)
est_coefs_kns = BQ2_grid%*%ag_data_otpt_new_kns$train_mod$svfm_fit$theta_hat
# Heat maps for each of the true coefficients
par(mfrow = c(2,3))
# I also don't need the contour line of code, just by adding the argument contour = T for image2D does the job
# Creating a heatmap for the estimated coefficients based on the grid points
image2D(z = matrix(est_coefs_kns[,1],n1,n2), x = uu, y = vv, col = heat.colors(5), contour = T, main = "Intercept")
image2D(z = matrix(est_coefs_kns[,2],n1,n2), x = uu, y = vv, col = heat.colors(5), contour = T, main = "Precipitation")
image2D(z = matrix(est_coefs_kns[,3],n1,n2), x = uu, y = vv, col = heat.colors(5), contour = T, main = "Irrigation")
image2D(z = matrix(est_coefs_kns[,4],n1,n2), x = uu, y = vv, col = heat.colors(5), contour = T, main = "Beta 1")
image2D(z = matrix(est_coefs_kns[,5],n1,n2), x = uu, y = vv, col = heat.colors(5), contour = T, main = "Beta 2")
image2D(z = matrix(est_coefs_kns[,6],n1,n2), x = uu, y = vv, col = heat.colors(5), contour = T, main = "Beta 3")
# ggplot(data = midw_cnty_dat, mapping = aes(x = long, y = lat)) +
#   geom_sf()
#   #geom_polygon(color="black")
#install.packages("rnaturalearthdata")
library(rnaturalearthdata)
# Obtaining the county data for the midwest states
midw_county_poly = counties(state = c("Kansas", "Illinois", "Indiana", "Iowa", "Missouri"), cb = TRUE)
ggplot(data = midw_county_poly) + geom_sf()
################# ADDING THE ESTIMATED COEFFICIENTS TO THE MIDWEST POLYGON DATA ###############
# Changing the county name and state name to lower case and removing punctuation so I can compare it with the regdat
midw_county_poly$NAME = tolower(gsub(" |'|\\.", "", midw_county_poly$NAME))
midw_county_poly$STATE_NAME = tolower(midw_county_poly$STATE_NAME)
head(midw_county_poly)
# I need to add the beta's to the midw_county_poly matrix to make sure that  I can fill according to those variables.
midw_county_poly[,c("alpha0","alpha1","alpha2", "beta1", "beta2", "beta3", "beta4", "beta5")] = 0
for(i in 1:nrow(est_coefs_midw_cent)){
cnty_coefs = est_coefs_midw_cent[i,]$county
state_coefs = est_coefs_midw_cent[i,]$State
for(j in 1:nrow(midw_county_poly)){
cnty_poly = midw_county_poly[j,]$NAME
state_poly = midw_county_poly[j,]$STATE_NAME
if(cnty_coefs == cnty_poly & state_coefs == state_poly){
# Adding the first 7 columns to midw_county_poly which represent alpha0,alpha1,beta1,.....,beta5
midw_county_poly[j,c("alpha0","alpha1","alpha2","beta1", "beta2", "beta3", "beta4", "beta5")] = est_coefs_midw_cent[i,1:8]
}
}
}
load("Data_Extraction_cleaning/RdataFiles/RawMidwestFundatPreProc_incl_irrig.RData")
load("Data_Extraction_cleaning/RdataFiles/RawMidwestRegdatPreProc_incl_irrig.RData")
load("Data_Extraction_cleaning/RdataFiles/MidwestScaledTriangulation.RData")
#### Creating eigenfunction plots for Midwest ########
# load("Data_Extraction_cleaning/RdataFiles/RawMidwestFundatPreProc_incl_irrig.RData")
# load("Data_Extraction_cleaning/RdataFiles/RawMidwestRegdatPreProc_incl_irrig.RData")
# load("Data_Extraction_cleaning/RdataFiles/MidwestScaledTriangulation.RData")
midw_years = length(unique(midw_regdat_new$Year))
ag.data.cv_otpt_midw = ag.data_cv.fxn_nopresmooth(fundat_all = midw_fd_new, nonfd = midw_regdat_new,  n_yr = midw_years,
sp_tri = midw_scl_tri, n_fold = 5, iter = 1, deg = 3, DE_MEAN_RESP = T,
pred_vars = c("avgPRCP","irrig_prop"),reval = c(0,1), fld_lim = 1, thresh = 0.90)
